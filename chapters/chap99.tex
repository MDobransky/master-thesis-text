\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}

Our work can be summarized in five segments. We started by reviewing related work and other relevant image processing models based on deep learning. We continued by weighting the options for improving SSD, where we decided to replace VGG feature extractor by a more modern network. Then we took a look at the relationship between detected classes and detector performance. In the fourth part, we returned to improving SSD, this time we focused on one base network, and instead of using the classification network as is, we make a series of adjustments aimed at improving the performance. We dedicated the final part of this work to designing and implementing a version of SSD detector with the use of temporal information.

\subsubsection*{Model review}
We began by briefly summarizing the development of classification networks by presenting a selection of models while describing their architecture and historical significance. After we covered the bases of image processing, we moved on to region-based object detection and compiled a brief overview of R-CNN family of networks.

Since the focus of this thesis is to optimize the SSD detector for video surveillance, we presented an in-depth examination of this detector. However, it would not be right to present SSD without mentioning its contemporary counterpart, YOLO. Because both SSD and YOLO are one-stage detectors and our experience shows that the one-stage approach can be challenging to comprehend, we compiled a detailed examination of this approach.

In order to gain more extensive knowledge about video detection and inspiration for our work, we also examined a pair of video detectors exploiting the temporal information in the video.

\subsubsection*{Feature Extraction Network}
We know, from the research paper introducing SSD, that the precision of the model can be improved by implementing a sophisticated data augmentation algorithm. Since augmentation algorithms slow down the training process, we decided to advance with a fast and simple augmentation and instead focus on the relative comparison of model performances. To obtain a benchmark baseline, we began our work by re-implementing SSD in PyTorch framework and trained it on COCO dataset.

Our first steps towards optimizing SSD led to a search for a replacement for the underlying outdated VGG classifier. We tried out ResNet networks, Xception and NASNet-Mobile. The testing revealed that all versions of SSD based on ResNet are capable of outperforming standard SSD, but Xception and NASNet only outperform VGG in terms of speed. Although this result suggested ResNet as a clear winner, achieving 32.7\% mAP and 50fps over original 29.7\% mAP and 45fps, we were not satisfied with all the results and further pursued the possibilities for improvement, mainly for the Xception-SSD. 

\subsubsection*{Classes}
Before we continued with testing of architecture modifications, we decided to take a side-step toward the training data. As stated before, our baseline SSD is trained on COCO dataset. However, we are not interested in every class provided by COCO. As a matter of fact, we are only interested in seven of those eighty classes.

Before we moved to this smaller dataset, we took this opportunity and performed two tests concerning the impact of limiting the number of detected classes. The first experiment was based on our hypothesis, according to which the removal of the unwanted classes from the training process can harm the precision of the detector. The second test was to observe the relationship between the number of detected classes and the speed of the network.

The results of the precision test on were inconclusive for our test setup and did not favor one dataset over the other. However, the inference speed test clearly shows the benefits of a lower number of classes. With ResNet50-SSD, we managed to speed up the network from 50 fps on 80 classes to 123 fps on 7 classes. Based on the results of those tests, we decided to continue further testing with this limited dataset.

\subsubsection*{Model Modifications}
Although ResNet was the best performer in our first tests, we decided to try and improve the Xception-based SSD, since Xception looked promising in classification benchmarks and our SSD implementation showed disappointing precision. We already ruled out the option of keeping both SSD and Xception unmodified. We performed some experiments with modified detection but did not receive any positive results. Therefore we decided to adjust the feature extraction part of the network to fit the needs of SSD better.

We took an experimental approach and designed multiple versions of Xception to test. After a few iterations, we arrived at the Xception version H. This version managed to reach 49.8\% mAP and perform on par with ResNet50-SSD's 48.7\% mAP while being about 15\% slower.

Although this experiment did not result in the model that would manage to outperform ResNet substantially, we learned a lot about the relationship between classification models and detection ones. The fact is that not every state-of-the-art classification network is fit to serve as a feature extractor for an object detector like SSD, mainly if said detector uses multiple feature maps at different scales. Some networks like NASNet-Mobile may be downright unfit, and others need adjustment to fit the needs of the detector.

\subsubsection*{Temporal Detection}
In the final chapter of this thesis, we turned our attention to video detectors with the use of temporal information provided by the continuity of surveillance video. Based on the knowledge we gained from the experiments with SSD and reviewing the temporal models, we designed our version of the temporal detector. We based it on ResNet34 feature extractor, with SSD-like detection, extended by three-dimensional temporal convolution for consecutive frames. We named our approach \textit{Single Shot Detector with Temporal Convolution} (SSDTC).

Testing our design, we observed a significant precision improvement over regular ResNet34-SSD on HollywoodHeads dataset. SSD reached 81.2\% mAP, while SSDTC managed to achieve 86.8\%. This result is comparable to 86.7\% of reviewed Tube-CNN. Furthermore, Tube-CNN performs at less than 10 fps which is significantly less than our speed of 111 fps. 

We believe our model to be a successful proof of concept and see a lot of opportunities for future work to further enhance its performance.


\section*{Future Work}
Although our experiments were successful in both improving the SSD detector and proving the viability of more advanced temporal detection, it left a lot of room for further improvements. Here, we provide a few suggestions for future work.

\begin{itemize}
\item Explore further optimizations of ResNet architecture for SSD.

\item Improve the precision by expanding the dataset and implementing a more sophisticated and varied augmentation algorithm for training.

\item Explore the options of redesigning the SSDTC architecture to avoid repetitive processing of frames. 

\item Measure the impact of temporal window size in SSDTC and a possibility of adding padding in the temporal dimension of three-dimensional convolution.

\item Speed up the detection through implementation improvements. For example, implement pre- and post-processing operations on GPU or re-implement the network in a fast framework optimized for inference, e.g., TensorRT.
\end{itemize}

\section*{Applications}
In the introduction, we mentioned many interesting and useful applications of object detectors.  In this section, we present a selection of additional applications that directly use object detection and build on top of it to generate more complex information about the processed video.

\begin{description}
\item[Tracking] Thanks to the nature of the video, we expect to be able to locate and track objects in time, observe their direction and speed. The purpose of the tracking is to connect detections from individual frames into a set of continuous trajectories. A tracker can use the centralized bounding-box positions and match those points into a trajectory using a recursive probability estimation, i.e., the Kalman filter \cite{bib:kalman}.

\item[Re-Identification] Re-identification is an extension of the tracking problem to objects passing between fields of view of multiple cameras. Regions inside bounding boxes predicted by an object detector can be used by the DeepReID \cite{bib:reid} or other similar algorithms, to find the matching object.

\item[Search] An automatic annotation of video frames by an object detector can also be used for interactive video retrieval \cite{bib:lokoc} in large video collections.
For example, the ability of the detector to learn to recognize a set of classes with bounding boxes can be used for sketch based search \cite{bibi:vidsearch} \cite{bib:visione}.

\end{description}
